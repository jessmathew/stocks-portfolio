---
title: 'GR5261 - Statistical Methods in Finance: Stocks Portfolio'
author: 
  - Jess Mathew
  - jm4742
date: "June 4, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries
```{r}
library(tools)
library(zoo)
library(forecast)
library(tidyverse)
library(PerformanceAnalytics)
library(dplyr)
library(corrr)
library(tseries)
library(xts)
library(quantmod)
library(PortfolioAnalytics)
library(ROI)
library(ROI.plugin.glpk)
library(ROI.plugin.quadprog)
library(ROI.plugin.symphony)
library(tsbox)
library(reshape2)
```

# Merge all the individual files together to create two datasets. (1) Date and Adjusted Close Price (2) Date and Volume
```{r eval=FALSE}
multMergeDateAndAdjustedClosePrice <- function(mypath) {
  filenames<-list.files(path=mypath, full.names=TRUE)
  datalist <- lapply(filenames, function(x){
    stockData <- read.csv(file=x,header=T)[,c("date", "adjclose")]
    colnames(stockData)[2] <- file_path_sans_ext(basename(x))
    return (stockData)
    })
  Reduce(function(x,y) {
    merge(x,y, by.x = "date", by.y = "date", all = TRUE)
    }, datalist)
}

multMergeDateAndVolume <- function(mypath) {
  filenames<-list.files(path=mypath, full.names=TRUE)
  datalist <- lapply(filenames, function(x){
    stockData <- read.csv(file=x,header=T)[,c("date", "volume")]
    colnames(stockData)[2] <- file_path_sans_ext(basename(x))
    return (stockData)
    })
  Reduce(function(x,y) {
    merge(x,y, by.x = "date", by.y = "date", all = TRUE)
    }, datalist)
}

dateAndAdjustedClosePriceData <- multMergeDateAndAdjustedClosePrice("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\fh_20190420\\full_history")

dateAndVolumeData <- multMergeDateAndVolume("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\fh_20190420\\full_history")

write.csv(dateAndAdjustedClosePriceData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files\\DateAndAdjustedClosePriceData.csv", row.names = FALSE)

write.csv(dateAndVolumeData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files\\DateAndVolumeData.csv", row.names = FALSE)
```

# Read the data files and order them by date.
```{r eval=FALSE}
setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files")

dateAndAdjustedClosePriceData <- read.csv(file="DateAndAdjustedClosePriceData.csv", header=TRUE, sep=",")
dateAndAdjustedClosePriceDataOrderedByDate <- dateAndAdjustedClosePriceData[order(dateAndAdjustedClosePriceData$date),]

dateAndVolumeData <- read.csv(file="DateAndVolumeData.csv", header=TRUE, sep=",")
dateAndVolumeDataOrderedByDate <- dateAndVolumeData[order(dateAndVolumeData$date),]

write.csv(dateAndAdjustedClosePriceDataOrderedByDate,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files\\DateAndAdjustedClosePriceDataOrderedByDate.csv", row.names = FALSE)

write.csv(dateAndVolumeDataOrderedByDate,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files\\DateAndVolumeDataOrderedByDate.csv", row.names = FALSE)
```

# Take the final ten years of data and remove assets which have five percent or more of the data missing. Remove assets which have less than 1,000 volume for 5% or more of the ten year period.
```{r eval=FALSE}
setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files")
dateAndAdjustedClosePriceDataOrderedByDate <- read.csv(file="DateAndAdjustedClosePriceDataOrderedByDate.csv", header=TRUE, sep=",")
dateAndVolumeDataOrderedByDate <- read.csv(file="DateAndVolumeDataOrderedByDate.csv", header=TRUE, sep=",")

numberOfDays <- nrow(dateAndAdjustedClosePriceDataOrderedByDate)
financialDaysInYear <- 252
financialDaysInTenYears <- financialDaysInYear*10

lastDayInTheFinalTenYearPeriod <- numberOfDays
firstDayInTheFinalTenYearPeriod <- lastDayInTheFinalTenYearPeriod - financialDaysInTenYears

dateAndAdjustedClosePriceDataOrderedByDateForFinalTenYearPeriod <- dateAndAdjustedClosePriceDataOrderedByDate[firstDayInTheFinalTenYearPeriod:lastDayInTheFinalTenYearPeriod, ]

columnNamesWithNinetyFivePercentOfAdjustedClosePriceDataAvailable <- colnames(dateAndAdjustedClosePriceDataOrderedByDateForFinalTenYearPeriod)[as.data.frame(colSums(is.na(dateAndAdjustedClosePriceDataOrderedByDateForFinalTenYearPeriod))/financialDaysInTenYears) <= 0.05]

dateAndVolumeDataOrderedByDateForFinalTenYearPeriod <- dateAndVolumeDataOrderedByDate[firstDayInTheFinalTenYearPeriod:lastDayInTheFinalTenYearPeriod, ]
dateAndVolumeDataOrderedByDateForFinalTenYearPeriod[is.na(dateAndVolumeDataOrderedByDateForFinalTenYearPeriod)] <- 0
dateAndVolumeDataOrderedByDateForFinalTenYearPeriod <- apply(dateAndVolumeDataOrderedByDateForFinalTenYearPeriod, 2, function(x) ifelse(x < 1000, "NA", x))

columnNamesWithNinetyFivePercentOfVolumeDataNotLiquid <- colnames(dateAndVolumeDataOrderedByDateForFinalTenYearPeriod)[as.data.frame(colSums(is.na(dateAndVolumeDataOrderedByDateForFinalTenYearPeriod))/financialDaysInTenYears) <= 0.05]

columnNamesForStocksThatAreVettedToUseInAnalysis <- intersect(as.vector(columnNamesWithNinetyFivePercentOfAdjustedClosePriceDataAvailable), as.vector(columnNamesWithNinetyFivePercentOfAdjustedClosePriceDataAvailable))

finalTenYearsStockHistoryForRelevantStocksConsecutiveNAValues <- subset(dateAndAdjustedClosePriceDataOrderedByDateForFinalTenYearPeriod, select=columnNamesForStocksThatAreVettedToUseInAnalysis)

write.csv(finalTenYearsStockHistoryForRelevantStocksConsecutiveNAValues,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files\\FinalTenYearsStockHistoryForRelevantStocksConsecutiveNAValues.csv", row.names = FALSE)
```

# Remove assets where there are too many consecutive NA values
```{r eval=FALSE}
setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files")
finalTenYearsStockHistoryData <- read.csv(file="FinalTenYearsStockHistoryForRelevantStocksConsecutiveNAValues.csv", header=TRUE, sep=",")

columnIndexes <- seq(1,ncol(finalTenYearsStockHistoryData))

columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen <- c()
for (columnIndex in columnIndexes)
{
  stockDataForIteration <- finalTenYearsStockHistoryData[,columnIndex]
  naBreakdown <- rle(is.na(stockDataForIteration))
  if(naBreakdown$lengths >= 10 & naBreakdown$values == TRUE) {
      columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen[columnIndex] <- -columnIndex
    }
}
columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen <- columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen[!is.na(columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen)]

finalTenYearsStockHistoryData <- finalTenYearsStockHistoryData[columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen]

write.csv(finalTenYearsStockHistoryData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files\\FinalTenYearsStockHistoryForRelevantStocksNoNAValues.csv", row.names = FALSE)
```

# Fill in the missing NA values with reasonable estimates. For the columns where NA is the first value, we need to manually delete those. Approximately 3 columns with 10 NA values in total between the 3 columns.
```{r eval=FALSE}
setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files")
finalTenYearsStockHistoryData <- read.csv(file="FinalTenYearsStockHistoryForRelevantStocksNoNAValues.csv", header=TRUE, sep=",")

columnNames <- colnames(finalTenYearsStockHistoryData)

for (columnName in columnNames)
{
  finalTenYearsStockHistoryData <- finalTenYearsStockHistoryData %>% fill(columnName) #default direction down
}

write.csv(finalTenYearsStockHistoryData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files\\FilteredStockHistoryDataForTheFinalTenYearsWithNoGaps.csv", row.names = FALSE)
```

# Compute the daily log returns using adjusted close prices. 
```{r eval=FALSE}
setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files")
finalTenYearsStockHistoryData <- read.csv(file="FilteredStockHistoryDataForTheFinalTenYearsWithNoGaps.csv", header=TRUE, sep=",", colClasses=c("Date",rep("numeric",3909)))

dailyLogReturns <- data.frame(
   cbind.data.frame(
     finalTenYearsStockHistoryData$date[-1],
     diff(as.matrix(log(finalTenYearsStockHistoryData[,-1])))
     )
   )
names(dailyLogReturns)[1]<-"date"

write.csv(dailyLogReturns,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files\\FullLogStockAssetDataPossibleNAValues.csv", row.names = FALSE)
```

# Need to remove columns that have too many NA values in them at this point, in the log data file. Just remove all columns with NA's in them at this point, after taking the logs.
```{r eval=FALSE}
setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files")
finalTenYearsStockHistoryData <- read.csv(file="FullLogStockAssetDataPossibleNAValues.csv", header=TRUE, sep=",")

finalTenYearsStockHistoryData <- finalTenYearsStockHistoryData[ , colSums(is.na(finalTenYearsStockHistoryData)) == 0]

write.csv(finalTenYearsStockHistoryData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files\\FullLogStockAssetDataFilteredForNA.csv", row.names = FALSE)
```

# Detect and replace the outliers with estimates that are more consistent with the majority of the data
```{r eval=FALSE}
setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files")
fullLogAssetData <- read.csv(file="FullLogStockAssetDataFilteredForNA.csv", header=TRUE, sep=",", colClasses=c("Date",rep("numeric",3906)))

winsor1 <- function (x, fraction=.05)
{
   if(length(fraction) != 1 || fraction < 0 ||
         fraction > 0.5) {
      stop("bad value for 'fraction'")
   }
   lim <- quantile(x, probs=c(fraction, 1-fraction))
   x[ x < lim[1] ] <- lim[1]
   x[ x > lim[2] ] <- lim[2]
   x
}

columnIndexes <- seq(2,ncol(fullLogAssetData))

for (columnIndex in columnIndexes) {
  fullLogAssetData[,columnIndex] <- winsor1(fullLogAssetData[,columnIndex])
}

write.csv(fullLogAssetData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files\\FullLogStockAssetDataFittedForOutliers.csv", row.names = FALSE)
```

# Portfolio Optimization
```{r eval=FALSE}

options(scipen = 999)
setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files")
fittedFullLogAssetData <- read.csv(file="FullLogStockAssetDataFittedForOutliers.csv", header=TRUE, sep=",", colClasses=c("Date",rep("numeric",3906)))[-1,]

numberOfRows <- nrow(fittedFullLogAssetData)
numberOfColumns <- ncol(fittedFullLogAssetData)

h <- 5
m <- 252

# breakingCondition <- numberOfRows + h

index <- 0

stockIndexesForFirstLoop <- seq(2,numberOfColumns)
listOftotalReturnsForEachForecastedPeriod <- list()
while (TRUE)
{
  print("While loop index")
  print(index)
  print(Sys.time())
  startRow <- (h*index) + 1
  endRow <- (h*index) + m

  assetsDataForCurrentTimePeriod <- fittedFullLogAssetData[startRow:endRow,]
  sharpeRatiosWithStockIndex <- data.frame(Stock=character(), SharpeRatio= as.double(double()), stringsAsFactors=FALSE)[stockIndexesForFirstLoop,]
  
  for (stockIndexForFirstLoop in stockIndexesForFirstLoop)
  {
    currentAssetDataForStockIndex <- assetsDataForCurrentTimePeriod[,c(1,stockIndexForFirstLoop)]
    columnName <- colnames(currentAssetDataForStockIndex)[2]
    sharpeRatiosWithStockIndex[nrow(sharpeRatiosWithStockIndex)+1, ] <- c(columnName, (mean(currentAssetDataForStockIndex[,2]))/(sd(currentAssetDataForStockIndex[,2])))
  }
  
  stockNamesWithHighestSharpeRatios <- sharpeRatiosWithStockIndex %>% arrange(desc(SharpeRatio))
  stockNamesWithHighestSharpeRatios <- data.frame(head(stockNamesWithHighestSharpeRatios, 30))

  stocksWithHighestSharpeRatios <- subset(assetsDataForCurrentTimePeriod, select=stockNamesWithHighestSharpeRatios[,1])

  correlationBetweenTheStocks <- stocksWithHighestSharpeRatios %>% correlate(use = "everything") %>% stretch() %>% arrange(abs(r))

  namesOfLowlyCorrelatedStocks <- data.frame(stack(correlationBetweenTheStocks[1:2]))[,1] %>% unique()
  namesOfLowlyCorrelatedStocks <- data.frame(head(namesOfLowlyCorrelatedStocks, 30))
  
  stocksToUseForModeling <- assetsDataForCurrentTimePeriod[, as.vector(namesOfLowlyCorrelatedStocks[,1])]
  stocksToUseForModelingWithDateAppended <- data.frame(assetsDataForCurrentTimePeriod[,1], stocksToUseForModeling)
  stocksToUseForModelingXTS <- xts(stocksToUseForModelingWithDateAppended[,-1], order.by=stocksToUseForModelingWithDateAppended[,1])
  
  stockIndexesForSecondLoop <- seq(1:ncol(stocksToUseForModeling))
  forecastedLogReturnsForStocksList = list()
  
  for(stockIndexForSecondLoop in stockIndexesForSecondLoop) {
    print("Second loop index")
    print(stockIndexForSecondLoop)
    currentStock <- stocksToUseForModeling[stockIndexForSecondLoop]
    columnName <- colnames(currentStock)
  
    meanOfCurentStock <- mean(unlist(currentStock))
    sdOfCurrentStock <- sd(unlist(currentStock))
    
    loopIndex <- seq(1:h)
    price<-rep(NA,h)
    
    for(i in loopIndex){
      
      if (i == 1)
      {
        price[i]<-as.numeric(unlist(currentStock[length(currentStock),]))*exp(rnorm(1,meanOfCurentStock,sdOfCurrentStock))
      }
      else
      {
        price[i]<-price[i-1]*exp(rnorm(1,meanOfCurentStock,sdOfCurrentStock)) 
      }
    }
    
    forcastedLogReturnsForCurrentStock<-as.data.frame(cbind(price))
    colnames(forcastedLogReturnsForCurrentStock)[colnames(forcastedLogReturnsForCurrentStock)=="x"] <- columnName
    forecastedLogReturnsForStocksList[[stockIndexForSecondLoop]] <- forcastedLogReturnsForCurrentStock
  }
  
  forecastedLogReturnsForStocks <- dplyr::bind_cols(forecastedLogReturnsForStocksList)
  forecastedLogReturnsForStocks <- as.matrix.data.frame(forecastedLogReturnsForStocks)
  
  tickers <- colnames(stocksToUseForModeling)
  
  meanReturns <- colMeans(stocksToUseForModeling)
  covMat <- cov(stocksToUseForModeling)
  
  columnSumsOfStocksToUseForModeling <- as.data.frame(colSums(stocksToUseForModeling))
  weightsForPortfolio <- as.data.frame(sweep(columnSumsOfStocksToUseForModeling,2,colSums(columnSumsOfStocksToUseForModeling),`/`))
  
  # weightsForPortfolio <- data.frame(matrix(ncol = 1, nrow = 30))
  # weightsForPortfolio[] <- 1/30
  
  totalReturnsForTheForecastingWindowByDay <- as.matrix(forecastedLogReturnsForStocks) %*% as.matrix(weightsForPortfolio)

  totalReturnForTheForecastingWindow <- unname(colSums(totalReturnsForTheForecastingWindowByDay))
  listOftotalReturnsForEachForecastedPeriod[[index+1]] <- totalReturnForTheForecastingWindow
  
  index <- index + 1
  if (index == 455)
    # if (endRow > 257)
  {
    break
  }
}

totalReturnsForEachForecastedPeriod <- dplyr::bind_cols(listOftotalReturnsForEachForecastedPeriod)
totalReturnsForEachForecastedPeriod <- as.data.frame(totalReturnsForEachForecastedPeriod)

totalReturnsForEachForecastedPeriod

write.csv(totalReturnsForEachForecastedPeriod,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files\\ForecastedPortfolioReturnsEqualWeights.csv", row.names = FALSE)
```

```{r eval=FALSE}
options(scipen = 999)
setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files")
fittedFullLogAssetData <- read.csv(file="FullLogStockAssetDataFittedForOutliers.csv", header=TRUE, sep=",", colClasses=c("Date",rep("numeric",3906)))[-1,]

numberOfRows <- nrow(fittedFullLogAssetData)
numberOfColumns <- ncol(fittedFullLogAssetData)

h <- 5
m <- 252

# breakingCondition <- numberOfRows + h

index <- 0

stockIndexesForFirstLoop <- seq(2,numberOfColumns)
listOftotalReturnsForEachForecastedPeriod <- list()
while (TRUE)
{
  print("While loop index")
  print(index)
  print(Sys.time())
  startRow <- (h*index) + 1
  endRow <- (h*index) + m

  assetsDataForCurrentTimePeriod <- fittedFullLogAssetData[startRow:endRow,]
  sharpeRatiosWithStockIndex <- data.frame(Stock=character(), SharpeRatio= as.double(double()), stringsAsFactors=FALSE)[stockIndexesForFirstLoop,]
  
  for (stockIndexForFirstLoop in stockIndexesForFirstLoop)
  {
    currentAssetDataForStockIndex <- assetsDataForCurrentTimePeriod[,c(1,stockIndexForFirstLoop)]
    columnName <- colnames(currentAssetDataForStockIndex)[2]
    sharpeRatiosWithStockIndex[nrow(sharpeRatiosWithStockIndex)+1, ] <- c(columnName, (mean(currentAssetDataForStockIndex[,2]))/(sd(currentAssetDataForStockIndex[,2])))
  }
  
  stockNamesWithHighestSharpeRatios <- sharpeRatiosWithStockIndex %>% arrange(desc(SharpeRatio))
  stockNamesWithHighestSharpeRatios <- data.frame(head(stockNamesWithHighestSharpeRatios, 30))

  stocksWithHighestSharpeRatios <- subset(assetsDataForCurrentTimePeriod, select=stockNamesWithHighestSharpeRatios[,1])

  correlationBetweenTheStocks <- stocksWithHighestSharpeRatios %>% correlate(use = "everything") %>% stretch() %>% arrange(abs(r))

  namesOfLowlyCorrelatedStocks <- data.frame(stack(correlationBetweenTheStocks[1:2]))[,1] %>% unique()
  namesOfLowlyCorrelatedStocks <- data.frame(head(namesOfLowlyCorrelatedStocks, 30))
  
  stocksToUseForModeling <- assetsDataForCurrentTimePeriod[, as.vector(namesOfLowlyCorrelatedStocks[,1])]
  stocksToUseForModelingWithDateAppended <- data.frame(assetsDataForCurrentTimePeriod[,1], stocksToUseForModeling)
  stocksToUseForModelingXTS <- xts(stocksToUseForModelingWithDateAppended[,-1], order.by=stocksToUseForModelingWithDateAppended[,1])
  
  stockIndexesForSecondLoop <- seq(1:ncol(stocksToUseForModeling))
  forecastedLogReturnsForStocksList = list()
  
  for(stockIndexForSecondLoop in stockIndexesForSecondLoop) {
    print("Second loop index")
    print(stockIndexForSecondLoop)
    currentStock <- stocksToUseForModeling[stockIndexForSecondLoop]
    columnName <- colnames(currentStock)
  
    meanOfCurentStock <- mean(unlist(currentStock))
    sdOfCurrentStock <- sd(unlist(currentStock))
    
    loopIndex <- seq(1:h)
    price<-rep(NA,h)
    
    for(i in loopIndex){
      
      if (i == 1)
      {
        price[i]<-as.numeric(unlist(currentStock[length(currentStock),]))*exp(rnorm(1,meanOfCurentStock,sdOfCurrentStock))
      }
      else
      {
        price[i]<-price[i-1]*exp(rnorm(1,meanOfCurentStock,sdOfCurrentStock)) 
      }
    }
    
    forcastedLogReturnsForCurrentStock<-as.data.frame(cbind(price))
    colnames(forcastedLogReturnsForCurrentStock)[colnames(forcastedLogReturnsForCurrentStock)=="x"] <- columnName
    forecastedLogReturnsForStocksList[[stockIndexForSecondLoop]] <- forcastedLogReturnsForCurrentStock
  }
  
  forecastedLogReturnsForStocks <- dplyr::bind_cols(forecastedLogReturnsForStocksList)
  forecastedLogReturnsForStocks <- as.matrix.data.frame(forecastedLogReturnsForStocks)
  
  tickers <- colnames(stocksToUseForModeling)
  
  meanReturns <- colMeans(stocksToUseForModeling)
  covMat <- cov(stocksToUseForModeling)
  
  columnSumsOfStocksToUseForModeling <- as.data.frame(colSums(stocksToUseForModeling))
  # weightsForPortfolio <- as.data.frame(sweep(columnSumsOfStocksToUseForModeling,2,colSums(columnSumsOfStocksToUseForModeling),`/`))
  
  weightsForPortfolio <- data.frame(matrix(ncol = 1, nrow = 30))
  weightsForPortfolio[] <- 1/30
  
  totalReturnsForTheForecastingWindowByDay <- as.matrix(forecastedLogReturnsForStocks) %*% as.matrix(weightsForPortfolio)

  totalReturnForTheForecastingWindow <- unname(colSums(totalReturnsForTheForecastingWindowByDay))
  listOftotalReturnsForEachForecastedPeriod[[index+1]] <- totalReturnForTheForecastingWindow
  
  index <- index + 1
  if (index == 455)
    # if (endRow > 257)
  {
    break
  }
}

totalReturnsForEachForecastedPeriod <- dplyr::bind_cols(listOftotalReturnsForEachForecastedPeriod)
totalReturnsForEachForecastedPeriod <- as.data.frame(totalReturnsForEachForecastedPeriod)

totalReturnsForEachForecastedPeriod

write.csv(totalReturnsForEachForecastedPeriod,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\Final Data Files\\ForecastedPortfolioReturnsEqualWeights.csv", row.names = FALSE)
```

```{r}

## Merge all the indivdual files together to create the date and adjust. 

# multmerge <- function(mypath) {
#   filenames<-list.files(path=mypath, full.names=TRUE)
#   datalist <- lapply(filenames, function(x){
#     stockData <- read.csv(file=x,header=T)[,c("date", "adjclose")]
#     colnames(stockData)[2] <- file_path_sans_ext(basename(x))
#     return (stockData)
#     })
#   Reduce(function(x,y) {
#     merge(x,y, by.x = "date", by.y = "date", all = TRUE)
#     }, datalist)
# }
# 
# mymergeddata <- multmerge("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\fh_20190420\\full_history")
# head(mymergeddata)
#

# write.csv(mymergeddata,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\FullStockHistory.csv", row.names = FALSE)

## Read the full stock history data and order it, to make a new data set that I can run my analysis on.
# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# fullStockHistoryData <- read.csv(file="FullStockHistory.csv", header=TRUE, sep=",")
# orderedFullStockHistoryData <- fullStockHistoryData[order(fullStockHistoryData$date),]
# head(orderedFullStockHistoryData)

# write.csv(orderedFullStockHistoryData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\OrderedFullStockHistory.csv", row.names = FALSE)

## This section containts a loop that basically finds the ten year period that has the most assets with 5% or less of the data being missing.
# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# orderedFullStockHistoryData <- read.csv(file="OrderedSampleStockHistory.csv", header=TRUE, sep=",")
# 
# numberOfDays <- nrow(orderedFullStockHistoryData)
# numberOfDays
# 
# days <- seq(1:numberOfDays)
# financialDaysInYear <- 252
# financialDaysInTenYears <- financialDaysInYear*10
# 
# dateRangeDataFrame <- data.frame(InitialDay = 0, FinalDay = 0, NAPercentagesLessThanFivePercentCount = 0)
# 
# for (initialDay in days) {
#   finalDay <- initialDay + (financialDaysInTenYears - 1)
#   
#   stockAssetDataForCurrentTenYearPeriod <- orderedFullStockHistoryData[initialDay:finalDay, ]
#   
#   naPercentages <- sapply(stockAssetDataForCurrentTenYearPeriod, function(y) sum(length(which(is.na(y))))/financialDaysInTenYears)
#   
#   countOfNAPercentagesLessThanFivePercent <- sum(naPercentages <= 0.05)
#   
#   if (dateRangeDataFrame[3] < countOfNAPercentagesLessThanFivePercent) {
#     dateRangeDataFrame[1] = initialDay
#     dateRangeDataFrame[2] = finalDay
#     dateRangeDataFrame[3] = countOfNAPercentagesLessThanFivePercent
#   }
# }
# 
# dateRangeDataFrame

## Check the final ten years of stock history to see how many assets have 5% or less of their data missing. We then write the file so that we can just read from it later, instead of recomputing to find the algorithm. 
# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# orderedFullStockHistoryData <- read.csv(file="OrderedSampleStockHistory.csv", header=TRUE, sep=",")
# 
# numberOfDays <- nrow(orderedFullStockHistoryData)
# financialDaysInYear <- 252
# financialDaysInTenYears <- financialDaysInYear*10
# 
# lastDayInTheFinalTenYearPeriod <- numberOfDays
# firstDayInTheFinalTenYearPeriod <- lastDayInTheFinalTenYearPeriod - financialDaysInTenYears
# 
# stockAssetDataForFinalTenYearPeriod <- orderedFullStockHistoryData[firstDayInTheFinalTenYearPeriod:lastDayInTheFinalTenYearPeriod, ]
# 
# columnNamesWithNinetyFivePercentOfDataAvailable <- colnames(stockAssetDataForFinalTenYearPeriod)[as.data.frame(colSums(is.na(stockAssetDataForFinalTenYearPeriod))/financialDaysInTenYears) <= 0.05]
# 
# finalTenYearsStockHistoryForRelevantStocks <- subset(stockAssetDataForFinalTenYearPeriod, select=columnNamesWithNinetyFivePercentOfDataAvailable)
# 
# write.csv(finalTenYearsStockHistoryForRelevantStocks,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\SampleFinalTenYearsStockHistoryForRelevantStocks.csv", row.names = FALSE)

## Remove asset data where there are too many consecutive NA values.

# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# # finalTenYearsStockHistoryData <- read.csv(file="FinalTenYearsStockHistoryForRelevantStocks.csv", header=TRUE, sep=",", colClasses=c("Date",rep("numeric",4019)))
# finalTenYearsStockHistoryData <- read.csv(file="FinalTenYearsStockHistoryForRelevantStocks.csv", header=TRUE, sep=",")
# 
# columnIndexes <- seq(1,ncol(finalTenYearsStockHistoryData))
# 
# columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen <- c()
# for (columnIndex in columnIndexes)
# {
#   stockDataForIteration <- finalTenYearsStockHistoryData[,columnIndex]
#   naBreakdown <- rle(is.na(stockDataForIteration))
#   if(naBreakdown$lengths >= 10 & naBreakdown$values == TRUE) {
#       columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen[columnIndex] <- -columnIndex
#     }
# }
# columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen <- columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen[!is.na(columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen)]
# 
# finalTenYearsStockHistoryData <- finalTenYearsStockHistoryData[columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen]
# 
# write.csv(finalTenYearsStockHistoryData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\FilteredStockHistoryDataForTheFinalTenYears.csv", row.names = FALSE)

## Fill in the missing NA values with reasonable estimates. For the columns where NA is the first value, we need to manually delete those. Approximately 3 columns with 10 NA values in total between the 3 columns.

# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# # finalTenYearsStockHistoryData <- read.csv(file="FilteredStockHistoryDataForTheFinalTenYears.csv", header=TRUE, sep=",", colClasses=c("date",rep("numeric",3909)))
# # finalTenYearsStockHistoryData <- read.csv(file="FilteredStockHistoryDataForTheFinalTenYears.csv", header=TRUE, sep=",")
# finalTenYearsStockHistoryData <- read.csv(file="FilteredStockHistoryDataForTheFinalTenYears.csv", header=TRUE, sep=",")
# 
# columnNames <- colnames(finalTenYearsStockHistoryData)
# 
# for (columnName in columnNames)
# {
#   finalTenYearsStockHistoryData <- finalTenYearsStockHistoryData %>% fill(columnName) #default direction down
# }
# 
# write.csv(finalTenYearsStockHistoryData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\FilteredStockHistoryDataForTheFinalTenYearsWithNoGaps.csv", row.names = FALSE)

## Compute the daily log returns using adjusted close prices. 
# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# finalTenYearsStockHistoryData <- read.csv(file="TESTFilteredStockHistoryDataForTheFinalTenYearsWithNoGaps.csv", header=TRUE, sep=",", colClasses=c("Date",rep("numeric",3909)))
# 
# head(finalTenYearsStockHistoryData)
# 
# dailyLogReturns <- data.frame(
#    cbind.data.frame(
#      finalTenYearsStockHistoryData$date[-1],
#      diff(as.matrix(log(finalTenYearsStockHistoryData[,-1])))
#      )
#    )
# names(dailyLogReturns)[1]<-"date"
# 
# head(dailyLogReturns)
# 
# write.csv(dailyLogReturns,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\FullLogStockAssetData.csv", row.names = FALSE)

## Need to remove columns that have too many NA values in them at this point, in the log data file. Just remove all columns with NA's in them at this point, after taking the logs.

# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# finalTenYearsStockHistoryData <- read.csv(file="FullLogStockAssetData.csv", header=TRUE, sep=",")
# 
# finalTenYearsStockHistoryData <- finalTenYearsStockHistoryData[ , colSums(is.na(finalTenYearsStockHistoryData)) == 0]
# 
# write.csv(finalTenYearsStockHistoryData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\FullLogStockAssetDataFilteredForNA.csv", row.names = FALSE)

## Detect and replace the outliers with estimates that are more consistent with the majority of the data

# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# fullLogAssetData <- read.csv(file="FullLogStockAssetDataFilteredForNA.csv", header=TRUE, sep=",", colClasses=c("Date",rep("numeric",3906)))

# winsor1 <- function (x, fraction=.05)
# {
#    if(length(fraction) != 1 || fraction < 0 ||
#          fraction > 0.5) {
#       stop("bad value for 'fraction'")
#    }
#    lim <- quantile(x, probs=c(fraction, 1-fraction))
#    x[ x < lim[1] ] <- lim[1]
#    x[ x > lim[2] ] <- lim[2]
#    x
# }
# 
# columnIndexes <- seq(2,ncol(fullLogAssetData))
# 
# for (columnIndex in columnIndexes) {
#   fullLogAssetData[,columnIndex] <- winsor1(fullLogAssetData[,columnIndex])
# }
# 
# write.csv(fullLogAssetData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\FittedFullLogStockAssetData.csv", row.names = FALSE)

# ## Now we look into portfolio optimization.
# 
# options(scipen = 999)
# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# fittedFullLogAssetData <- read.csv(file="FittedFullLogStockAssetData.csv", header=TRUE, sep=",", colClasses=c("Date",rep("numeric",3906)))
# dim(fittedFullLogAssetData)
# fittedFullLogAssetData <- fittedFullLogAssetData[-1,]
# dim(fittedFullLogAssetData)
# 
# 
# numberOfRows <- nrow(fittedFullLogAssetData)
# numberOfColumns <- ncol(fittedFullLogAssetData)
# 
# 
# h <- 5
# m <- 252
# 
# breakingCondition <- numberOfRows + h
# 
# index <- 0
# 
# listOftotalReturnsForEachForecastedPeriod <- list()
# while (TRUE)
# {
#   stockIndexes <- seq(2,numberOfColumns)
#   
#   startRow <- (h*index) + 1
#   endRow <- (h*index) + m
#   
#   assetsDataForCurrentTimePeriod <- fittedFullLogAssetData[startRow:endRow,]
#   sharpeRatiosWithStockIndex <- data.frame(Stock=character(), SharpeRatio= as.double(double()), stringsAsFactors=FALSE)
#   
#   for (stockIndex in stockIndexes)
#   {
#     currentAssetDataForStockIndex <- assetsDataForCurrentTimePeriod[,c(1,stockIndex)]
#     currentAssetDataForStockIndexTimeSeries <- ts(currentAssetDataForStockIndex)
#     columnName <- colnames(currentAssetDataForStockIndex)[2]
#     
#     sharpeRatio <- round(SharpeRatio(currentAssetDataForStockIndexTimeSeries, Rf = .0003, FUN="StdDev"), 4)
#     
#     sharpeRatiosWithStockIndex[nrow(sharpeRatiosWithStockIndex)+1, ] <- c(columnName, sharpeRatio[1,2])
#   }
#   
#   stockNamesWithHighestSharpeRatios <- sharpeRatiosWithStockIndex %>% arrange(desc(SharpeRatio))
#   stockNamesWithHighestSharpeRatios <- data.frame(head(stockNamesWithHighestSharpeRatios, 50))
# 
#   stocksWithHighestSharpeRatios <- subset(assetsDataForCurrentTimePeriod, select=stockNamesWithHighestSharpeRatios[,1])
# 
#   correlationBetweenTheStocks <- stocksWithHighestSharpeRatios %>% correlate() %>% stretch() %>% arrange(abs(r))
# 
#   namesOfLowlyCorrelatedStocks <- data.frame(stack(correlationBetweenTheStocks[1:2]))[,1] %>% unique()
#   namesOfLowlyCorrelatedStocks <- data.frame(head(namesOfLowlyCorrelatedStocks, 30))
# 
#   stocksToUseForModeling <- assetsDataForCurrentTimePeriod[, as.vector(namesOfLowlyCorrelatedStocks[,1])]
#   stocksToUseForModelingWithDateAppended <- data.frame(assetsDataForCurrentTimePeriod[,1], stocksToUseForModeling)
#   stocksToUseForModelingXTS <- xts(stocksToUseForModelingWithDateAppended[,-1], order.by=stocksToUseForModelingWithDateAppended[,1])
# 
#   stockIndexes <- seq(1:ncol(stocksToUseForModeling))
# 
#   forecastedLogReturnsForStocksList = list()
#   for(stockIndex in stockIndexes)
#   {
#     currentStock <- stocksToUseForModeling[stockIndex]
#     columnName <- colnames(currentStock)
# 
#     currentStockWithDateAppendedXTS <-xts(currentStock, order.by=stocksToUseForModelingWithDateAppended[,1])
# 
#     modelARIMA <- auto.arima(currentStockWithDateAppendedXTS)
#     forecastARIMA <- forecast(modelARIMA, h=h)
# 
#     forcastedLogReturnsForCurrentStock <- as.data.frame(forecastARIMA$mean)
#     colnames(forcastedLogReturnsForCurrentStock)[colnames(forcastedLogReturnsForCurrentStock)=="x"] <- columnName
# 
#     forecastedLogReturnsForStocksList[[stockIndex]] <- forcastedLogReturnsForCurrentStock
#   }
# 
#   forecastedLogReturnsForStocks <- dplyr::bind_cols(forecastedLogReturnsForStocksList)
#   forecastedLogReturnsForStocks <- as.matrix.data.frame(forecastedLogReturnsForStocks)
# 
#   tickers <- colnames(stocksToUseForModeling)
# 
#   meanReturns <- colMeans(stocksToUseForModeling)
#   covMat <- cov(stocksToUseForModeling)
# 
#   portf <- portfolio.spec(tickers)
#   portf <- add.constraint(portf, type="full_investment")
#   portf <- add.constraint(portf, type ="box", min=.01, max=.05)
#   portf <- add.objective(portf, type="return", name="mean")
#   portf <- add.objective(portf, type="risk", name="StdDev")
# 
#   # optPort <- optimize.portfolio(stocksToUseForModelingXTS, portf, optimize_method = "ROI", trace=TRUE)
#   optPort <- optimize.portfolio(stocksToUseForModelingXTS, portf, optimize_method='random',maxSR=TRUE, message=TRUE)
# 
#   weightsForPortfolio <- as.data.frame(extractWeights(optPort))
#   
#   print(weightsForPortfolio)
# 
#   totalReturnsForTheForecastingWindowByDay <- as.matrix(forecastedLogReturnsForStocks) %*% as.matrix(weightsForPortfolio)
# 
#   totalReturnForTheForecastingWindow <- unname(colSums(totalReturnsForTheForecastingWindowByDay))
#   listOftotalReturnsForEachForecastedPeriod[[index+1]] <- totalReturnForTheForecastingWindow
# 
#   # if (endRow > breakingCondition)
#   if (endRow > 272)
#   {
#     break
#   }
#   index <- index + 1
# }
# 
# totalReturnsForEachForecastedPeriod <- dplyr::bind_cols(listOftotalReturnsForEachForecastedPeriod)
# totalReturnsForEachForecastedPeriod <- as.data.frame(totalReturnsForEachForecastedPeriod)
# 
# write.csv(totalReturnsForEachForecastedPeriod,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\MyPortfolioReturns.csv", row.names = FALSE)
```