---
title: 'GR5261 - Statistical Methods in Finance: Stocks Portfolio'
author: 
  - Jess Mathew
  - jm4742
date: "June 4, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(zoo)
library(forecast)
library(tidyverse)
library(PerformanceAnalytics)
library(dplyr)
library(corrr)

## Merge all the indivdual files together to create my initial data set. 

# library(tools)

# multmerge <- function(mypath) {
#   filenames<-list.files(path=mypath, full.names=TRUE)
#   datalist <- lapply(filenames, function(x){
#     stockData <- read.csv(file=x,header=T)[,c("date", "adjclose")]
#     colnames(stockData)[2] <- file_path_sans_ext(basename(x))
#     return (stockData)
#     })
#   Reduce(function(x,y) {
#     merge(x,y, by.x = "date", by.y = "date", all = TRUE)
#     }, datalist)
# }
# 
# mymergeddata <- multmerge("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\fh_20190420\\full_history")
# head(mymergeddata)
#

# write.csv(mymergeddata,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\FullStockHistory.csv", row.names = FALSE)

## Read the full stock history data and order it, to make a new data set that I can run my analysis on.
# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# fullStockHistoryData <- read.csv(file="FullStockHistory.csv", header=TRUE, sep=",")
# orderedFullStockHistoryData <- fullStockHistoryData[order(fullStockHistoryData$date),]
# head(orderedFullStockHistoryData)

# write.csv(orderedFullStockHistoryData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\OrderedFullStockHistory.csv", row.names = FALSE)

## This section containts a loop that basically finds the ten year period that has the most assets with 5% or less of the data being missing.
# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# orderedFullStockHistoryData <- read.csv(file="OrderedSampleStockHistory.csv", header=TRUE, sep=",")
# 
# numberOfDays <- nrow(orderedFullStockHistoryData)
# numberOfDays
# 
# days <- seq(1:numberOfDays)
# financialDaysInYear <- 252
# financialDaysInTenYears <- financialDaysInYear*10
# 
# dateRangeDataFrame <- data.frame(InitialDay = 0, FinalDay = 0, NAPercentagesLessThanFivePercentCount = 0)
# 
# for (initialDay in days) {
#   finalDay <- initialDay + (financialDaysInTenYears - 1)
#   
#   stockAssetDataForCurrentTenYearPeriod <- orderedFullStockHistoryData[initialDay:finalDay, ]
#   
#   naPercentages <- sapply(stockAssetDataForCurrentTenYearPeriod, function(y) sum(length(which(is.na(y))))/financialDaysInTenYears)
#   
#   countOfNAPercentagesLessThanFivePercent <- sum(naPercentages <= 0.05)
#   
#   if (dateRangeDataFrame[3] < countOfNAPercentagesLessThanFivePercent) {
#     dateRangeDataFrame[1] = initialDay
#     dateRangeDataFrame[2] = finalDay
#     dateRangeDataFrame[3] = countOfNAPercentagesLessThanFivePercent
#   }
# }
# 
# dateRangeDataFrame

## Check the final ten years of stock history to see how many assets have 5% or less of their data missing. We then write the file so that we can just read from it later, instead of recomputing to find the algorithm. 
# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# orderedFullStockHistoryData <- read.csv(file="OrderedSampleStockHistory.csv", header=TRUE, sep=",")
# 
# numberOfDays <- nrow(orderedFullStockHistoryData)
# financialDaysInYear <- 252
# financialDaysInTenYears <- financialDaysInYear*10
# 
# lastDayInTheFinalTenYearPeriod <- numberOfDays
# firstDayInTheFinalTenYearPeriod <- lastDayInTheFinalTenYearPeriod - financialDaysInTenYears
# 
# stockAssetDataForFinalTenYearPeriod <- orderedFullStockHistoryData[firstDayInTheFinalTenYearPeriod:lastDayInTheFinalTenYearPeriod, ]
# 
# columnNamesWithNinetyFivePercentOfDataAvailable <- colnames(stockAssetDataForFinalTenYearPeriod)[as.data.frame(colSums(is.na(stockAssetDataForFinalTenYearPeriod))/financialDaysInTenYears) <= 0.05]
# 
# finalTenYearsStockHistoryForRelevantStocks <- subset(stockAssetDataForFinalTenYearPeriod, select=columnNamesWithNinetyFivePercentOfDataAvailable)
# 
# write.csv(finalTenYearsStockHistoryForRelevantStocks,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\SampleFinalTenYearsStockHistoryForRelevantStocks.csv", row.names = FALSE)

## Remove asset data where there are too many consecutive NA values.

# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# # finalTenYearsStockHistoryData <- read.csv(file="FinalTenYearsStockHistoryForRelevantStocks.csv", header=TRUE, sep=",", colClasses=c("Date",rep("numeric",4019)))
# finalTenYearsStockHistoryData <- read.csv(file="FinalTenYearsStockHistoryForRelevantStocks.csv", header=TRUE, sep=",")
# 
# columnIndexes <- seq(1,ncol(finalTenYearsStockHistoryData))
# 
# columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen <- c()
# for (columnIndex in columnIndexes)
# {
#   stockDataForIteration <- finalTenYearsStockHistoryData[,columnIndex]
#   naBreakdown <- rle(is.na(stockDataForIteration))
#   if(naBreakdown$lengths >= 10 & naBreakdown$values == TRUE) {
#       columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen[columnIndex] <- -columnIndex
#     }
# }
# columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen <- columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen[!is.na(columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen)]
# 
# finalTenYearsStockHistoryData <- finalTenYearsStockHistoryData[columnIndexesWhereConsecutiveNAsAreGreaterThanOrEqualToTen]
# 
# write.csv(finalTenYearsStockHistoryData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\FilteredStockHistoryDataForTheFinalTenYears.csv", row.names = FALSE)

## Fill in the missing NA values with reasonable estimates. For the columns where NA is the first value, we need to manually delete those. Approximately 3 columns with 10 NA values in total between the 3 columns.

# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# # finalTenYearsStockHistoryData <- read.csv(file="FilteredStockHistoryDataForTheFinalTenYears.csv", header=TRUE, sep=",", colClasses=c("date",rep("numeric",3909)))
# # finalTenYearsStockHistoryData <- read.csv(file="FilteredStockHistoryDataForTheFinalTenYears.csv", header=TRUE, sep=",")
# finalTenYearsStockHistoryData <- read.csv(file="FilteredStockHistoryDataForTheFinalTenYears.csv", header=TRUE, sep=",")
# 
# columnNames <- colnames(finalTenYearsStockHistoryData)
# 
# for (columnName in columnNames)
# {
#   finalTenYearsStockHistoryData <- finalTenYearsStockHistoryData %>% fill(columnName) #default direction down
# }
# 
# write.csv(finalTenYearsStockHistoryData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\FilteredStockHistoryDataForTheFinalTenYearsWithNoGaps.csv", row.names = FALSE)

## Compute the daily log returns using adjusted close prices. 
# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# finalTenYearsStockHistoryData <- read.csv(file="TESTFilteredStockHistoryDataForTheFinalTenYearsWithNoGaps.csv", header=TRUE, sep=",", colClasses=c("Date",rep("numeric",3909)))
# 
# head(finalTenYearsStockHistoryData)
# 
# dailyLogReturns <- data.frame(
#    cbind.data.frame(
#      finalTenYearsStockHistoryData$date[-1],
#      diff(as.matrix(log(finalTenYearsStockHistoryData[,-1])))
#      )
#    )
# names(dailyLogReturns)[1]<-"date"
# 
# head(dailyLogReturns)
# 
# write.csv(dailyLogReturns,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\FullLogStockAssetData.csv", row.names = FALSE)

## Need to remove columns that have too many NA values in them at this point, in the log data file. Just remove all columns with NA's in them at this point, after taking the logs.

# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# finalTenYearsStockHistoryData <- read.csv(file="FullLogStockAssetData.csv", header=TRUE, sep=",")
# 
# finalTenYearsStockHistoryData <- finalTenYearsStockHistoryData[ , colSums(is.na(finalTenYearsStockHistoryData)) == 0]
# 
# write.csv(finalTenYearsStockHistoryData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\FullLogStockAssetDataFilteredForNA.csv", row.names = FALSE)

## Detect and replace the outliers with estimates that are more consistent with the majority of the data

# setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
# fullLogAssetData <- read.csv(file="FullLogStockAssetDataFilteredForNA.csv", header=TRUE, sep=",", colClasses=c("Date",rep("numeric",3906)))

# winsor1 <- function (x, fraction=.05)
# {
#    if(length(fraction) != 1 || fraction < 0 ||
#          fraction > 0.5) {
#       stop("bad value for 'fraction'")
#    }
#    lim <- quantile(x, probs=c(fraction, 1-fraction))
#    x[ x < lim[1] ] <- lim[1]
#    x[ x > lim[2] ] <- lim[2]
#    x
# }
# 
# columnIndexes <- seq(2,ncol(fullLogAssetData))
# 
# for (columnIndex in columnIndexes) {
#   fullLogAssetData[,columnIndex] <- winsor1(fullLogAssetData[,columnIndex])
# }
# 
# write.csv(fullLogAssetData,"C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories\\FittedFullLogStockAssetData.csv", row.names = FALSE)

## Now we look into portfolio optimization.

options(scipen = 999)
setwd("C:\\Users\\jessm\\OneDrive\\Documents\\Columbia University\\Summer 2019\\GR5261 - Statistical Methods in Finance\\Take Home Project\\AMEX NYSE NASDAQ Stock Histories")
fittedFullLogAssetData <- read.csv(file="FittedFullLogStockAssetData.csv", header=TRUE, sep=",", colClasses=c("Date",rep("numeric",3906)))
dim(fittedFullLogAssetData)
fittedFullLogAssetData <- fittedFullLogAssetData[-1,]
dim(fittedFullLogAssetData)


numberOfRows <- nrow(fittedFullLogAssetData)
numberOfColumns <- ncol(fittedFullLogAssetData)

stockIndexes <- seq(2,numberOfColumns)

h <- 5
m <- 252

breakingCondition <- numberOfRows + h

index <- 0

startRow <- (h*index) + 1
endRow <- (h*index) + m

assetsDataForCurrentTimePeriod <- fittedFullLogAssetData[startRow:endRow,]
sharprRatiosWithStockIndex <- data.frame(Stock=character(), SharpeRatio= as.double(double()), stringsAsFactors=FALSE)

for (stockIndex in stockIndexes)
{
  currentAssetDataForStockIndex <- assetsDataForCurrentTimePeriod[,c(1,stockIndex)]
  currentAssetDataForStockIndexTimeSeries <- ts(currentAssetDataForStockIndex)
  columnName <- colnames(currentAssetDataForStockIndex)[2]
    
  sharpeRatio <- round(SharpeRatio(currentAssetDataForStockIndexTimeSeries, Rf = .0003, FUN="StdDev"), 4)
  
  sharprRatiosWithStockIndex[nrow(sharprRatiosWithStockIndex)+1, ] <- c(columnName, sharpeRatio[1,2])
}

 stockNamesWithHighestSharpeRatios <- sharprRatiosWithStockIndex %>%
    arrange(desc(SharpeRatio)) %>%
    slice(1:50)
 
 stocksWithHighestSharpeRatios <- subset(assetsDataForCurrentTimePeriod, select=stockNamesWithHighestSharpeRatios[,1])
 
 tmp <- cor(stocksWithHighestSharpeRatios)
 tmp
 
 correlationBetweenTheStocks <- stocksWithHighestSharpeRatios %>%
    correlate() %>% 
    stretch() %>% 
    arrange(abs(r))
 
 namesOfLowlyCorrelatedStocks <- data.frame(stack(correlationBetweenTheStocks[1:2]))[1] %>% distinct() %>% slice(1:30)
 stocksToUseForModeling <- subset(assetsDataForCurrentTimePeriod, select=namesOfLowlyCorrelatedStocks[,1])
 
 dim(stocksToUseForModeling)

# while (index < breakingCondition)
# {
#   startRow <- (h*index) + 1
#   endRow <- (h*index) + m
#   
#   assetsDataForCurrentTimePeriod <- fittedFullLogAssetData[startRow:endRow,]
#   
#   for (stockIndex in stockIndexes)
#   {
#     currentAssetDataForStockIndex <- assetsDataForCurrentTimePeriod[,stockIndex]
#     
#     fit <- lm(currentAssetDataForStockIndex ~ assetsDataForCurrentTimePeriod)
#     result <- summary(fit)
#     # summary gives us a lot of useful information, but we're mostly in beta value !!
#     beta <- result$coefficients[2,1]
#     print(beta)
#   }
#   
#   if (endRow > breakingCondition)
#   {
#     break
#   }
#   index <- index + 1
# }
```